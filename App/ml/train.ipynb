{
 "cells": [
  {
   "cell_type": "code",
   "id": "cf2efa8566c8b88d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T07:56:10.858701Z",
     "start_time": "2025-01-26T07:56:09.571456Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T07:56:10.982135Z",
     "start_time": "2025-01-26T07:56:10.975478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define the input and output directories\n",
    "input_dir = \"image\"\n",
    "output_dir = \"image/classified\"\n",
    "\n",
    "# Define the folders to process\n",
    "folders_to_process = [\"gem\", \"non_gem\"]\n"
   ],
   "id": "a511c8d613571e47",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T07:56:11.870376Z",
     "start_time": "2025-01-26T07:56:11.866159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the output image size\n",
    "output_size = (224, 224)"
   ],
   "id": "29312964ff5f3612",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T07:56:13.115587Z",
     "start_time": "2025-01-26T07:56:13.084220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def crop_image(image_path):\n",
    "            img = cv2.imread(image_path)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "            edges = cv2.Canny(gray, 50, 150)\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            xs = []\n",
    "            ys = []\n",
    "\n",
    "            for contour in contours:\n",
    "                # Calculate the area of the contour\n",
    "                area = cv2.contourArea(contour)\n",
    "\n",
    "                # Ignore small contours (noise)\n",
    "                if area > 0:\n",
    "                    # Calculate the x, y, w, h coordinates of the bounding rectangle\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    xs.append(x)\n",
    "                    xs.append(x + w)\n",
    "                    ys.append(y)\n",
    "                    ys.append(y + h)\n",
    "\n",
    "            if len(xs) > 0 and len(ys) > 0:\n",
    "\n",
    "                w = max(xs) - min(xs)\n",
    "                h = max(ys) - min(ys)\n",
    "\n",
    "                l = max(w, h)\n",
    "\n",
    "                xm = int((max(xs) + min(xs)) / 2)\n",
    "                ym = int((max(ys) + min(ys)) / 2)\n",
    "\n",
    "                x1 = xm - int(l/2)\n",
    "                x2 = xm + int(l/2)\n",
    "                y1 = ym - int(l/2)\n",
    "                y2 = ym + int(l/2)\n",
    "\n",
    "                if x1 < 0:\n",
    "                    x1 += abs(x1)\n",
    "                    x2 += abs(x1)\n",
    "                if y1 < 0:\n",
    "                    y1 += abs(y1)\n",
    "                    y2 += abs(y1)\n",
    "\n",
    "                cropped_img = img[y1:y2, x1:x2]\n",
    "            else:\n",
    "                cropped_img = img\n",
    "\n",
    "            resized_img = cv2.resize(cropped_img, output_size)\n",
    "\n",
    "            return resized_img"
   ],
   "id": "85f8491889ba52ea",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-26T08:01:39.534533Z",
     "start_time": "2025-01-26T07:56:15.299581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through each folder\n",
    "for folder in folders_to_process:\n",
    "    # Get the full path to the folder\n",
    "    folder_path = os.path.join(input_dir, folder)\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    output_folder_path = os.path.join(output_dir, folder)\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    # Iterate through each subfolder in the folder\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        # Get the full path to the subfolder\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "\n",
    "        # Create the output subfolder if it doesn't exist\n",
    "        output_subfolder_path = os.path.join(output_folder_path, subfolder)\n",
    "        if not os.path.exists(output_subfolder_path):\n",
    "            os.makedirs(output_subfolder_path)\n",
    "\n",
    "        # Iterate through each image in the subfolder\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                image_path = os.path.join(subfolder_path, filename)\n",
    "                cv2.imwrite(os.path.join(output_subfolder_path, filename), crop_image(image_path))\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T18:10:44.527688Z",
     "start_time": "2025-01-21T18:10:42.885661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the dataset path\n",
    "dataset_path = 'image/classified'\n",
    "\n",
    "# Define the flowers and non-flowers paths\n",
    "flowers_path = \"image/classified/gem\"\n",
    "non_flowers_path = \"image/classified/non_gem\"\n",
    "\n",
    "# Get the list of images in the flowers and non-flowers folders\n",
    "flowers_images = []\n",
    "for folder in os.listdir(flowers_path):\n",
    "    folder_path = os.path.join(flowers_path, folder)\n",
    "    for image in os.listdir(folder_path):\n",
    "        flowers_images.append(os.path.join(folder_path, image))\n",
    "\n",
    "non_flowers_images = []\n",
    "for folder in os.listdir(non_flowers_path):\n",
    "    folder_path = os.path.join(non_flowers_path, folder)\n",
    "    for image in os.listdir(folder_path):\n",
    "        non_flowers_images.append(os.path.join(folder_path, image))\n",
    "\n",
    "# Split the images into training, validation, and test sets\n",
    "train_flowers, temp_flowers = train_test_split(flowers_images, test_size=0.4, random_state=42)\n",
    "validation_flowers, test_flowers = train_test_split(temp_flowers, test_size=0.5, random_state=42)\n",
    "\n",
    "train_non_flowers, temp_non_flowers = train_test_split(non_flowers_images, test_size=0.4, random_state=42)\n",
    "validation_non_flowers, test_non_flowers = train_test_split(temp_non_flowers, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create the training, validation, and test folders\n",
    "train_path = os.path.join(dataset_path, 'rcnn/train')\n",
    "validation_path = os.path.join(dataset_path, 'rcnn/validation')\n",
    "test_path = os.path.join(dataset_path, 'rcnn/test')\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    os.makedirs(train_path)\n",
    "if not os.path.exists(validation_path):\n",
    "    os.makedirs(validation_path)\n",
    "if not os.path.exists(test_path):\n",
    "    os.makedirs(test_path)\n",
    "\n",
    "# Create the flowers and non-flowers folders inside the training, validation, and test folders\n",
    "train_flowers_path = os.path.join(train_path, 'gem')\n",
    "train_non_flowers_path = os.path.join(train_path, 'non_gem')\n",
    "validation_flowers_path = os.path.join(validation_path, 'gem')\n",
    "validation_non_flowers_path = os.path.join(validation_path, 'non_gem')\n",
    "test_flowers_path = os.path.join(test_path, 'gem')\n",
    "test_non_flowers_path = os.path.join(test_path, 'non_gem')\n",
    "\n",
    "if not os.path.exists(train_flowers_path):\n",
    "    os.makedirs(train_flowers_path)\n",
    "if not os.path.exists(train_non_flowers_path):\n",
    "    os.makedirs(train_non_flowers_path)\n",
    "if not os.path.exists(validation_flowers_path):\n",
    "    os.makedirs(validation_flowers_path)\n",
    "if not os.path.exists(validation_non_flowers_path):\n",
    "    os.makedirs(validation_non_flowers_path)\n",
    "if not os.path.exists(test_flowers_path):\n",
    "    os.makedirs(test_flowers_path)\n",
    "if not os.path.exists(test_non_flowers_path):\n",
    "    os.makedirs(test_non_flowers_path)\n",
    "\n",
    "# Move the images to the training, validation, and test folders\n",
    "for image in train_flowers:\n",
    "    filename = os.path.basename(image)\n",
    "    shutil.copy(image, train_flowers_path)\n",
    "\n",
    "for image in train_non_flowers:\n",
    "    filename = os.path.basename(image)\n",
    "    shutil.copy(image, train_non_flowers_path)\n",
    "\n",
    "for image in validation_flowers:\n",
    "    filename = os.path.basename(image)\n",
    "    shutil.copy(image, validation_flowers_path)\n",
    "\n",
    "for image in validation_non_flowers:\n",
    "    filename = os.path.basename(image)\n",
    "    shutil.copy(image, validation_non_flowers_path)\n",
    "\n",
    "for image in test_flowers:\n",
    "    filename = os.path.basename(image)\n",
    "    shutil.copy(image, test_flowers_path)\n",
    "\n",
    "for image in test_non_flowers:\n",
    "    filename = os.path.basename(image)\n",
    "    shutil.copy(image, test_non_flowers_path)"
   ],
   "id": "da1e29d52ccc7530",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T18:10:53.061435Z",
     "start_time": "2025-01-21T18:10:52.921392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define the image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create data generators for training, validation, and test sets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'rcnn/train'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['non_gem', 'gem']\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'rcnn/validation'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['non_gem', 'gem']\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'rcnn/test'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['non_gem', 'gem']\n",
    ")"
   ],
   "id": "44bfd7464b1be25a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 526 images belonging to 2 classes.\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 176 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T18:38:37.673184Z",
     "start_time": "2025-01-21T18:11:52.147180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create the RCNN model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Freeze the base layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_generator.samples // batch_size)\n",
    "\n",
    "print(f'Test loss: {test_loss:.3f}')\n",
    "print(f'Test accuracy: {test_acc:.3f}')\n",
    "\n",
    "# Save the model\n",
    "model.save('rcnn_model.h5')"
   ],
   "id": "ffa80ed1101ddc68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmr/SDK/Python/_venv/Gem/.venv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m196s\u001B[0m 12s/step - accuracy: 0.8076 - loss: 1.2456 - val_accuracy: 0.9375 - val_loss: 0.2431\n",
      "Epoch 2/10\n",
      "\u001B[1m 1/16\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m2:07\u001B[0m 8s/step - accuracy: 0.9688 - loss: 0.1502"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmr/SDK/Python/_venv/Gem/.venv/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m57s\u001B[0m 3s/step - accuracy: 0.9688 - loss: 0.1502 - val_accuracy: 0.9375 - val_loss: 0.3202\n",
      "Epoch 3/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m201s\u001B[0m 13s/step - accuracy: 0.9365 - loss: 0.2412 - val_accuracy: 0.9312 - val_loss: 0.3036\n",
      "Epoch 4/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 5s/step - accuracy: 0.9688 - loss: 0.1123 - val_accuracy: 0.9312 - val_loss: 0.3267\n",
      "Epoch 5/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m259s\u001B[0m 14s/step - accuracy: 0.9793 - loss: 0.0536 - val_accuracy: 0.9688 - val_loss: 0.0769\n",
      "Epoch 6/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 5s/step - accuracy: 0.9688 - loss: 0.0990 - val_accuracy: 0.9688 - val_loss: 0.0785\n",
      "Epoch 7/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m203s\u001B[0m 13s/step - accuracy: 0.9966 - loss: 0.0099 - val_accuracy: 0.9625 - val_loss: 0.1012\n",
      "Epoch 8/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m81s\u001B[0m 5s/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 0.9625 - val_loss: 0.0883\n",
      "Epoch 9/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m260s\u001B[0m 14s/step - accuracy: 0.9975 - loss: 0.0130 - val_accuracy: 0.9625 - val_loss: 0.1098\n",
      "Epoch 10/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m55s\u001B[0m 3s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9500 - val_loss: 0.1550\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 9s/step - accuracy: 0.9812 - loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.086\n",
      "Test accuracy: 0.975\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T13:11:39.007817Z",
     "start_time": "2025-01-22T13:11:27.810999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('rcnn_model.h5')\n",
    "\n",
    "# Load the image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Load the image from a file path\n",
    "def load_image(path):\n",
    "    img = crop_image(path)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    return img_array\n",
    "\n",
    "# Make a prediction on the image\n",
    "def make_prediction(path):\n",
    "    img_array = load_image(path)\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction\n",
    "\n",
    "print(\"======= Predictions ======\")\n",
    "paths = os.listdir('image/test')\n",
    "predictions = []\n",
    "for name in paths:\n",
    "    image_path = os.path.join('image/test', name)\n",
    "    prediction = list(make_prediction(image_path))\n",
    "    score = float(prediction[0][0])\n",
    "    is_gem = score > 0.5\n",
    "    predictions.append([image_path, f\"{'Gem' if is_gem else 'Non-gem'}\", score])\n",
    "\n",
    "    #\n",
    "    # print(f\"{image_path.rjust(12)} -> {prediction} -> {is_gem}\")\n",
    "    # Convert the prediction to a class label\n",
    "    # if prediction[0][0] > 0.5:\n",
    "    #     print(\"The image is a gem.\")\n",
    "    # else:\n",
    "    #     print(\"The image is not a gem.\")\n"
   ],
   "id": "30b79fb7cbe8d179",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Predictions ======\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1s/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 584ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 806ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 754ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 781ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 594ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 618ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 607ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 565ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 558ms/step\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T13:11:53.990553Z",
     "start_time": "2025-01-22T13:11:53.953720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(predictions, columns=['Image', 'Prediction', 'Score'])\n",
    "df"
   ],
   "id": "32df573fe5d6f02a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                Image Prediction     Score\n",
       "0  image/test/IMG_20250121_122222.jpg        Gem  0.908380\n",
       "1                 image/test/ruby.png        Gem  0.999978\n",
       "2                 image/test/coin.png    Non-gem  0.315042\n",
       "3                  image/test/pen.png        Gem  0.990088\n",
       "4                  image/test/gem.png        Gem  0.999999\n",
       "5             image/test/sapphire.png        Gem  0.999988\n",
       "6               image/test/coin-2.JPG    Non-gem  0.070320\n",
       "7                 image/test/tree.png        Gem  0.993571\n",
       "8                  image/test/car.png        Gem  0.999853\n",
       "9             image/test/IMG_9930.JPG    Non-gem  0.004736"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image/test/IMG_20250121_122222.jpg</td>\n",
       "      <td>Gem</td>\n",
       "      <td>0.908380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image/test/ruby.png</td>\n",
       "      <td>Gem</td>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image/test/coin.png</td>\n",
       "      <td>Non-gem</td>\n",
       "      <td>0.315042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image/test/pen.png</td>\n",
       "      <td>Gem</td>\n",
       "      <td>0.990088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image/test/gem.png</td>\n",
       "      <td>Gem</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>image/test/sapphire.png</td>\n",
       "      <td>Gem</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>image/test/coin-2.JPG</td>\n",
       "      <td>Non-gem</td>\n",
       "      <td>0.070320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>image/test/tree.png</td>\n",
       "      <td>Gem</td>\n",
       "      <td>0.993571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>image/test/car.png</td>\n",
       "      <td>Gem</td>\n",
       "      <td>0.999853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>image/test/IMG_9930.JPG</td>\n",
       "      <td>Non-gem</td>\n",
       "      <td>0.004736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T17:46:55.748131Z",
     "start_time": "2025-01-21T17:46:55.743375Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "28506ca653377a2d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
